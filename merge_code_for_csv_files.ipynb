{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "xTsiU4cf0Mcx",
        "outputId": "6ed160d1-38b1-4250-b992-351ddb8acd6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'Date Time (UTC+08:00)' not found in the merged data\n",
            "Merged tilt files successfully!\n",
            "Column 'Date Time (UTC+08:00)' not found in the merged data\n",
            "Merged crack files successfully!\n",
            "Waiting for next merge...\n",
            "Column 'Date Time (UTC+08:00)' not found in the merged data\n",
            "Merged tilt files successfully!\n",
            "Column 'Date Time (UTC+08:00)' not found in the merged data\n",
            "Merged crack files successfully!\n",
            "Waiting for next merge...\n",
            "Column 'Date Time (UTC+08:00)' not found in the merged data\n",
            "Merged tilt files successfully!\n",
            "Column 'Date Time (UTC+08:00)' not found in the merged data\n",
            "Merged crack files successfully!\n",
            "Waiting for next merge...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-440c2b288cc9>\u001b[0m in \u001b[0;36m<cell line: 107>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# Run the periodic merge process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mrun_periodic_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_zip_tilt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file_tilt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_zip_crack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file_crack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval_minutes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-440c2b288cc9>\u001b[0m in \u001b[0;36mrun_periodic_merge\u001b[0;34m(input_zip_tilt, output_file_tilt, input_zip_crack, output_file_crack, interval_minutes)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Sleep for the specified interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval_minutes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert minutes to seconds for sleep interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Provide the input zip files and the output file names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "def merge_tilt_files(input_folder_tilt, output_file_tilt, merged_files_tilt):\n",
        "    # Create an empty DataFrame to store merged data\n",
        "    merged_data = pd.DataFrame()\n",
        "\n",
        "    # Iterate through each file in the input folder\n",
        "    for file_name in os.listdir(input_folder_tilt):\n",
        "        if file_name.endswith('.csv') and ('DG1' in file_name or 'DG2' in file_name or 'DG3' in file_name):\n",
        "            if file_name not in merged_files_tilt:\n",
        "                file_path = os.path.join(input_folder_tilt, file_name)\n",
        "                # Read each CSV file into a DataFrame\n",
        "                data = pd.read_csv(file_path)\n",
        "                # Concatenate the data\n",
        "                merged_data = pd.concat([merged_data, data], ignore_index=True)\n",
        "                print(\"Merged tilt file:\", file_name)\n",
        "                # Add the merged file to the list\n",
        "                merged_files_tilt.append(file_name)\n",
        "\n",
        "    # Ensure 'Date Time (UTC+08:00)' column exists before grouping\n",
        "    if 'Date Time (UTC+08:00)' in merged_data.columns:\n",
        "        # Merge rows with the same date and time\n",
        "        merged_data = merged_data.groupby('Date Time (UTC+08:00)').sum().reset_index()\n",
        "    else:\n",
        "        print(\"Column 'Date Time (UTC+08:00)' not found in the merged data\")\n",
        "\n",
        "    # Replace zeros with NaNs\n",
        "    merged_data.replace(0, np.nan, inplace=True)\n",
        "\n",
        "    # Remove rows that are entirely NaN\n",
        "    merged_data.dropna(axis=0, how='all', inplace=True)\n",
        "\n",
        "    # Write the merged DataFrame to a new CSV file\n",
        "    merged_data.to_csv(output_file_tilt, index=False)\n",
        "    print(\"Merged tilt files successfully!\")\n",
        "\n",
        "def merge_crack_files(input_folder_crack, output_file_crack, merged_files_crack):\n",
        "    # Create an empty DataFrame to store merged data\n",
        "    merged_data = pd.DataFrame()\n",
        "\n",
        "    # Iterate through each file in the input folder\n",
        "    for file_name in os.listdir(input_folder_crack):\n",
        "        if file_name.endswith('.csv') and ('CM01' in file_name or 'CM02' in file_name or 'CM03' in file_name or 'CM04' in file_name):\n",
        "            if file_name not in merged_files_crack:\n",
        "                file_path = os.path.join(input_folder_crack, file_name)\n",
        "                # Read each CSV file into a DataFrame\n",
        "                data = pd.read_csv(file_path)\n",
        "                # Concatenate the data\n",
        "                merged_data = pd.concat([merged_data, data], ignore_index=True)\n",
        "                print(\"Merged crack file:\", file_name)\n",
        "                # Add the merged file to the list\n",
        "                merged_files_crack.append(file_name)\n",
        "\n",
        "    # Ensure 'Date Time (UTC+08:00)' column exists before grouping\n",
        "    if 'Date Time (UTC+08:00)' in merged_data.columns:\n",
        "        # Merge rows with the same date and time\n",
        "        merged_data = merged_data.groupby('Date Time (UTC+08:00)').sum().reset_index()\n",
        "    else:\n",
        "        print(\"Column 'Date Time (UTC+08:00)' not found in the merged data\")\n",
        "\n",
        "    # Replace zeros with NaNs\n",
        "    merged_data.replace(0, np.nan, inplace=True)\n",
        "\n",
        "    # Remove rows that are entirely NaN\n",
        "    merged_data.dropna(axis=0, how='all', inplace=True)\n",
        "\n",
        "    # Write the merged DataFrame to a new CSV file\n",
        "    merged_data.to_csv(output_file_crack, index=False)\n",
        "    print(\"Merged crack files successfully!\")\n",
        "\n",
        "def run_periodic_merge(input_folder_tilt, output_file_tilt, input_folder_crack, output_file_crack, interval_minutes):\n",
        "    # Initialize lists to keep track of merged files\n",
        "    merged_files_tilt = []\n",
        "    merged_files_crack = []\n",
        "\n",
        "    while True:\n",
        "        # Remove empty and non-CSV files before merging\n",
        "        remove_empty_and_non_csv_files(input_folder_tilt)\n",
        "        remove_empty_and_non_csv_files(input_folder_crack)\n",
        "\n",
        "        # Merge CSV files\n",
        "        merge_tilt_files(input_folder_tilt, output_file_tilt, merged_files_tilt)\n",
        "        merge_crack_files(input_folder_crack, output_file_crack, merged_files_crack)\n",
        "        print(\"Waiting for next merge...\")\n",
        "\n",
        "        # Sleep for the specified interval\n",
        "        time.sleep(interval_minutes * 60)  # Convert minutes to seconds for sleep interval\n",
        "\n",
        "def remove_empty_and_non_csv_files(folder_path):\n",
        "    # Iterate through each file in the folder\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Check if the file is a CSV file\n",
        "        if file_name.endswith('.csv'):\n",
        "            # Check if the CSV file is empty\n",
        "            if os.path.getsize(file_path) == 0:\n",
        "                # Remove empty CSV file\n",
        "                os.remove(file_path)\n",
        "                print(f\"Removed empty CSV file: {file_name}\")\n",
        "        else:\n",
        "            # Remove non-CSV files\n",
        "            os.remove(file_path)\n",
        "            print(f\"Removed non-CSV file: {file_name}\")\n",
        "\n",
        "# Provide the input folder containing CSV files and the output file name\n",
        "input_folder_tilt = r\"C:\\summer_training\\tilt_meter_data\"\n",
        "output_file_tilt = r\"C:\\summer_training\\tilt_meter_merged_data.csv\"\n",
        "\n",
        "input_folder_crack = r\"C:\\summer_training\\crack_meter_data\"\n",
        "output_file_crack = r\"C:\\summer_training\\crack_meter_merged_data.csv\"\n",
        "interval_minutes = 240  # Set the interval for periodic merge in minutes\n",
        "\n",
        "# Run the periodic merge process\n",
        "run_periodic_merge(input_folder_tilt, output_file_tilt, input_folder_crack, output_file_crack, interval_minutes)"
      ]
    }
  ]
}